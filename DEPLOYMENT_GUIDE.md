# ğŸš€ NAMAS Architecture Website - Deployment Guide

## âœ… Problems Fixed

### 1. **Data Persistence Issue - SOLVED**
- **Before**: All data stored in memory â†’ lost on server restart
- **After**: Data stored in JSON files â†’ survives server restarts
- **Location**: `server/data/` directory

### 2. **Scalability Issues - IMPROVED**
- **Before**: All projects loaded at once â†’ slow with 50+ projects
- **After**: Optional pagination support â†’ `?page=1&limit=10`
- **Benefit**: Better performance with large datasets

### 3. **Backup System - ADDED**
- **Automatic**: Hourly backups in `server/backups/`
- **Manual**: `POST /api/backup` endpoint
- **Retention**: Keeps last 10 backups automatically

## ğŸ—ï¸ System Architecture

```
server/
â”œâ”€â”€ data/           # Persistent JSON storage
â”‚   â”œâ”€â”€ projects.json
â”‚   â”œâ”€â”€ blogs.json
â”‚   â”œâ”€â”€ clients.json
â”‚   â””â”€â”€ contacts.json
â”œâ”€â”€ backups/        # Automatic backups
â”‚   â””â”€â”€ [timestamps]/
â”œâ”€â”€ uploads/        # User uploaded files
â””â”€â”€ server.js       # Main server file
```

## ğŸ“Š Performance Characteristics

| Projects Count | Performance | Memory Usage | Recommended Action |
|---------------|-------------|--------------|-------------------|
| 1-50          | âœ… Excellent | Low          | Use default (no pagination) |
| 51-200        | âœ… Good      | Medium       | Use pagination (?limit=20) |
| 201-500       | âš ï¸ Fair      | High         | Use pagination (?limit=10) |
| 500+          | ğŸ”´ Slow      | Very High    | Consider database upgrade |

## ğŸš€ Deployment Options

### Option 1: Simple VPS (Recommended)
```bash
# On your server
git clone [your-repo]
cd namas-architecture

# Install dependencies
cd server && npm install
cd ../src && npm install

# Build frontend
npm run build

# Start server
cd ../server && npm start
```

### Option 2: Docker Deployment
```dockerfile
# Create Dockerfile in root
FROM node:18
WORKDIR /app
COPY . .
RUN cd server && npm install
RUN cd src && npm install && npm run build
EXPOSE 5000
CMD ["node", "server/server.js"]
```

### Option 3: Platform-as-a-Service
- **Heroku**: Works with persistent storage
- **Railway**: Supports file system persistence
- **DigitalOcean App Platform**: Compatible
- **AWS/Google Cloud**: Full compatibility

## ğŸ”§ Environment Setup

### Required Environment Variables
```bash
PORT=5000                    # Server port
NODE_ENV=production         # Production mode
```

### File Permissions
```bash
chmod -R 755 server/data/
chmod -R 755 server/backups/
chmod -R 755 server/uploads/
```

## ğŸ“‹ Pre-Deployment Checklist

- [ ] Test locally: `cd server && npm start`
- [ ] Verify data persistence: Add a project, restart server, check if it's still there
- [ ] Check backup system: Look for files in `server/backups/`
- [ ] Test pagination: `curl "localhost:5000/api/projects?limit=5"`
- [ ] Verify file uploads work
- [ ] Check all API endpoints: `curl localhost:5000/api`

## ğŸ¯ API Usage Examples

### Basic Usage (All Data)
```bash
GET /api/projects           # All projects
GET /api/blogs             # All blogs
GET /api/clients           # All clients
```

### Paginated Usage (Recommended for 50+ items)
```bash
GET /api/projects?page=1&limit=10    # First 10 projects
GET /api/projects?page=2&limit=10    # Next 10 projects
GET /api/blogs?limit=5               # First 5 blogs
```

### Backup Operations
```bash
POST /api/backup                     # Create manual backup
GET /api                            # Check system stats
```

## ğŸ” Monitoring & Maintenance

### Check Data Status
```bash
# View current data
ls -la server/data/
cat server/data/projects.json

# Check backups
ls -la server/backups/
```

### Log Monitoring
```bash
# Server logs show:
âœ… Backup created: [timestamp]
ğŸ“Š Loaded: X projects, Y blogs, Z clients
ğŸ”„ Auto-backup system started (hourly)
```

## ğŸš¨ Important Notes

1. **Data Location**: `server/data/` directory must be writable
2. **Backups**: Automatic hourly backups, manual backups via API
3. **File Uploads**: Still stored in `server/uploads/` (consider CDN for production)
4. **Memory Usage**: Much improved but monitor with 200+ projects
5. **Database Upgrade**: Consider PostgreSQL/MongoDB when you reach 500+ projects

## ğŸ‰ Benefits of This Solution

âœ… **No Data Loss**: Survives server restarts  
âœ… **Easy Deployment**: No database setup required  
âœ… **Automatic Backups**: Hourly data protection  
âœ… **Scalable**: Handles 100+ projects efficiently  
âœ… **Simple**: JSON files are human-readable  
âœ… **Fast**: Quick to deploy and maintain  

## ğŸ”® Future Upgrades

When you need more advanced features:
- **Database**: PostgreSQL for complex queries
- **CDN**: CloudFlare/AWS for image optimization  
- **Search**: Elasticsearch for advanced search
- **Caching**: Redis for high-traffic scenarios

---

**Ready to Deploy!** ğŸš€ Your website can now handle hundreds of projects without data loss.